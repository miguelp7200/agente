# ğŸš€ Backend de Chatbot de Facturas Gasco

## ğŸ“‹ InformaciÃ³n General

- **Ãšltima actualizaciÃ³n**: 2 de octubre de 2025
- **Estado del sistema**: PRODUCTION READY âœ…
- **ADK Agent**: gcp-invoice-agent-app (versiÃ³n estable)
- **MCP Toolbox**: 49 herramientas operativas
- **BigQuery**: Arquitectura dual validada
- **URLs Firmadas**: Implementadas y funcionando âœ…
- **Token Tracking**: Sistema de monitoreo de costos implementado ğŸ†•

## ğŸ—ï¸ Arquitectura del Sistema

El backend del sistema de chatbot de facturas Gasco estÃ¡ compuesto por tres componentes principales:

1. **ADK (Application Development Kit)**: Framework para el desarrollo de agentes conversacionales con Gemini-2.5-Flash
2. **MCP (Model Context Protocol)**: Protocolo para la comunicaciÃ³n con modelos de lenguaje y herramientas BigQuery
3. **PDF Server**: Servicio para el procesamiento y descarga segura de documentos PDF y ZIP de facturas

Todos estos componentes se comunican con **Google Cloud Platform** para el almacenamiento y procesamiento de datos.

## ğŸ“ Estructura del Repositorio

```
invoice-backend/
â”œâ”€â”€ my-agents/
â”‚   â””â”€â”€ gcp-invoice-agent-app/      # Agente principal de facturas
â”‚       â”œâ”€â”€ agent.py                # ConfiguraciÃ³n del agente ADK
â”‚       â”œâ”€â”€ agent_prompt_config.py  # ConfiguraciÃ³n de prompts
â”‚       â””â”€â”€ conversation_callbacks.py # ğŸ†• Sistema de logging con tokens
â”‚
â”œâ”€â”€ mcp-toolbox/
â”‚   â”œâ”€â”€ tools_updated.yaml          # ConfiguraciÃ³n de 49 herramientas BigQuery
â”‚   â””â”€â”€ README.md                   # InformaciÃ³n sobre binarios MCP
â”‚
â”œâ”€â”€ deployment/
â”‚   â””â”€â”€ backend/
â”‚       â”œâ”€â”€ Dockerfile              # Imagen Docker para Cloud Run
â”‚       â”œâ”€â”€ start_backend.sh        # Script de inicio multi-servicio
â”‚       â”œâ”€â”€ deploy.ps1              # ğŸ†• Script de deploy automatizado
â”‚       â””â”€â”€ requirements.txt        # Dependencias del proyecto
â”‚
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ create_bigquery_infrastructure.py
â”‚   â”œâ”€â”€ setup_dataset_tabla.py
â”‚   â””â”€â”€ SETUP_INFRAESTRUCTURA.md
â”‚
â”œâ”€â”€ sql_schemas/                    # ğŸ†• Schemas de BigQuery
â”‚   â””â”€â”€ add_token_usage_fields.sql  # Schema de token tracking
â”‚
â”œâ”€â”€ sql_validation/                 # ğŸ†• Queries de validaciÃ³n
â”‚   â””â”€â”€ validate_token_usage_tracking.sql
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ TOKEN_USAGE_TRACKING.md     # ğŸ†• DocumentaciÃ³n de tokens
â”‚   â””â”€â”€ adk_api_documentation.json  # DocumentaciÃ³n de API ADK
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ cases/                      # Casos de prueba JSON
â”‚   â”œâ”€â”€ scripts/                    # Scripts PowerShell de testing
â”‚   â””â”€â”€ curl-tests/                 # Tests con curl
â”‚
â”œâ”€â”€ config.py                       # ConfiguraciÃ³n central del proyecto
â””â”€â”€ README.md                       # Este archivo
```

## âš™ï¸ Requisitos Previos

- Python 3.11+
- Docker
- Google Cloud SDK
- Acceso a Google Cloud Platform (proyecto agent-intelligence-gasco)
- Credenciales de servicio configuradas

## ğŸ”§ ConfiguraciÃ³n del Entorno

### 1. InstalaciÃ³n de Dependencias

```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
source venv/bin/activate          # Linux/Mac
.\venv\Scripts\Activate.ps1       # Windows

# Instalar dependencias
pip install -r requirements.txt
```

### 2. ConfiguraciÃ³n de Variables de Entorno

```bash
export GOOGLE_CLOUD_PROJECT_READ=datalake-gasco
export GOOGLE_CLOUD_PROJECT_WRITE=agent-intelligence-gasco
export GOOGLE_CLOUD_LOCATION=us-central1
# PDF_SERVER_PORT=8011  # DEPRECATED - Using signed URLs
```

## ğŸ” Sistema de ConfiguraciÃ³n

El proyecto utiliza un **sistema de configuraciÃ³n dual** que combina archivos YAML con variables de ambiente para mÃ¡xima flexibilidad:

### JerarquÃ­a de ConfiguraciÃ³n

```
Environment Variables (highest priority)
         â†“
   config/config.yaml
         â†“
   Code Defaults (lowest priority)
```

### Archivo de ConfiguraciÃ³n Principal

El archivo `config/config.yaml` contiene toda la configuraciÃ³n base del sistema:

```yaml
google_cloud:
  service_accounts:
    pdf_signer: adk-agent-sa@agent-intelligence-gasco.iam.gserviceaccount.com
  
bigquery:
  timeouts:
    query_deadline: 60.0  # segundos

gcs:
  time_sync:
    threshold_seconds: 60
  buffer_time:
    clock_skew_detected: 5  # minutos
    verification_failed: 3
    synchronized: 1
  retry:
    base_delay_seconds: 60
    max_delay_seconds: 300
    backoff_multiplier: 2.0
    request_timeout: 30
  download:
    timeout_large_files: 60

validation:
  max_url_length: 2000
  max_zip_url_length: 3000

vertex_ai:
  thinking:
    max_budget: 8192
```

### Variables de Ambiente (Overrides)

Las variables de ambiente **sobrescriben** valores del YAML. ConversiÃ³n automÃ¡tica:

```
YAML path: gcs.retry.base_delay_seconds
Env var:   GCS_RETRY_BASE_DELAY_SECONDS
```

**Ejemplo de uso:**

```bash
# Override service account para otro proyecto
export PDF_SIGNER_SERVICE_ACCOUNT="my-sa@my-project.iam.gserviceaccount.com"

# Aumentar timeouts para conexiones lentas
export BIGQUERY_TIMEOUTS_QUERY_DEADLINE="120.0"
export GCS_RETRY_REQUEST_TIMEOUT="60"
```

### Archivo .env.example

El archivo `.env.example` documenta **16 variables configurables**:

| CategorÃ­a | Variables | PropÃ³sito |
|-----------|-----------|-----------|
| **Service Accounts** | `PDF_SIGNER_SERVICE_ACCOUNT` | Service account para firmar URLs |
| **BigQuery** | `BIGQUERY_TIMEOUTS_QUERY_DEADLINE` | Timeout de queries |
| **GCS Time Sync** | `GCS_TIME_SYNC_THRESHOLD_SECONDS`<br/>`GCS_TIME_SYNC_CHECK_TIMEOUT` | SincronizaciÃ³n de reloj |
| **GCS Buffer Time** | `GCS_BUFFER_TIME_CLOCK_SKEW_DETECTED`<br/>`GCS_BUFFER_TIME_VERIFICATION_FAILED`<br/>`GCS_BUFFER_TIME_SYNCHRONIZED` | Buffers por estado de sync |
| **GCS Retry** | `GCS_RETRY_BASE_DELAY_SECONDS`<br/>`GCS_RETRY_MAX_DELAY_SECONDS`<br/>`GCS_RETRY_BACKOFF_MULTIPLIER`<br/>`GCS_RETRY_REQUEST_TIMEOUT` | LÃ³gica de reintentos |
| **GCS Download** | `GCS_DOWNLOAD_TIMEOUT_LARGE_FILES` | Timeouts de descarga |
| **Validation** | `VALIDATION_MAX_URL_LENGTH`<br/>`VALIDATION_MAX_ZIP_URL_LENGTH` | LÃ­mites de validaciÃ³n |
| **Vertex AI** | `VERTEX_AI_THINKING_MAX_BUDGET` | Budget mÃ¡ximo de reasoning |

### Logging de Overrides

Los overrides se registran automÃ¡ticamente en **nivel DEBUG**:

```python
# Habilitar logging de overrides
import logging
logging.basicConfig(level=logging.DEBUG)

# Output:
# DEBUG:src.core.config.yaml_config_loader:Config override: gcs.retry.base_delay_seconds=90 (via env var GCS_RETRY_BASE_DELAY_SECONDS)
```

### Migrar a Otro Proyecto GCP

Para usar este cÃ³digo en un proyecto diferente:

1. **Copiar `.env.example` a `.env`**:
   ```bash
   cp .env.example .env
   ```

2. **Modificar `config/config.yaml`** con tus project IDs:
   ```yaml
   google_cloud:
     read:
       project: tu-proyecto-lectura
     write:
       project: tu-proyecto-escritura
     service_accounts:
       pdf_signer: tu-sa@tu-proyecto.iam.gserviceaccount.com
   ```

3. **Overrides opcionales en `.env`** para valores especÃ­ficos del ambiente

4. **Validar configuraciÃ³n**:
   ```python
   from src.core.config import get_config
   config = get_config()
   config.print_summary()  # Muestra configuraciÃ³n cargada
   ```

### 3. ConfiguraciÃ³n de MCP Toolbox

Los archivos binarios de MCP Toolbox son necesarios para el funcionamiento del sistema, pero debido a su tamaÃ±o (~117MB) no estÃ¡n incluidos en el repositorio.

Sigue las instrucciones en `mcp-toolbox/README.md` para obtenerlos.

### 4. ConfiguraciÃ³n de BigQuery

La configuraciÃ³n de la infraestructura de BigQuery es necesaria para el almacenamiento de datos de facturas:

```bash
cd infrastructure
python create_bigquery_infrastructure.py
python setup_dataset_tabla.py
```

## ğŸš€ Despliegue

### Despliegue Local (Desarrollo)

```bash
# OpciÃ³n 1: Script automatizado (recomendado)
chmod +x deployment/backend/start_backend.sh
./deployment/backend/start_backend.sh

# OpciÃ³n 2: Servicios individuales
# Terminal 1: MCP Toolbox
./mcp-toolbox/toolbox --tools-file=./mcp-toolbox/tools_updated.yaml --port=5000

# Terminal 2: ADK Agent Server
adk api_server --host=0.0.0.0 --port=8080 my-agents --allow_origins="*"
```

### Despliegue en Google Cloud Run (ProducciÃ³n)

#### âœ… MÃ©todo Recomendado: Script de Deploy Automatizado

```powershell
# Windows PowerShell
cd deployment/backend
.\deploy.ps1 -AutoVersion

# Opciones disponibles:
# -AutoVersion: Genera versiÃ³n automÃ¡tica con timestamp
# -Version "v1.2.3": Especifica versiÃ³n manual
# -NoCache: Limpia cache de Docker antes de build
```

El script `deploy.ps1` realiza automÃ¡ticamente:
1. âœ… ConstrucciÃ³n de imagen Docker
2. âœ… Push a Artifact Registry
3. âœ… Deploy a Cloud Run con configuraciÃ³n optimizada
4. âœ… Versionado automÃ¡tico
5. âœ… ValidaciÃ³n de deployment

#### MÃ©todo Manual: Docker Build + Push + Deploy

```bash
# 1. Construir imagen Docker
docker build -f deployment/backend/Dockerfile \
  -t us-central1-docker.pkg.dev/agent-intelligence-gasco/invoice-chatbot/backend:latest .

# 2. Subir imagen a Artifact Registry
docker push us-central1-docker.pkg.dev/agent-intelligence-gasco/invoice-chatbot/backend:latest

# 3. Desplegar en Cloud Run
gcloud run deploy invoice-backend \
  --image us-central1-docker.pkg.dev/agent-intelligence-gasco/invoice-chatbot/backend:latest \
  --region us-central1 \
  --project agent-intelligence-gasco \
  --allow-unauthenticated \
  --port 8080 \
  --set-env-vars="GOOGLE_CLOUD_PROJECT_READ=datalake-gasco,GOOGLE_CLOUD_PROJECT_WRITE=agent-intelligence-gasco,GOOGLE_CLOUD_LOCATION=us-central1,IS_CLOUD_RUN=true" \
  --service-account adk-agent-sa@agent-intelligence-gasco.iam.gserviceaccount.com \
  --memory 2Gi \
  --cpu 2 \
  --timeout 3600s \
  --max-instances 10 \
  --concurrency 10
```

### ğŸ”§ ConfiguraciÃ³n de Service Account

El servicio usa la service account `adk-agent-sa@agent-intelligence-gasco.iam.gserviceaccount.com` con los siguientes permisos:

- **BigQuery Data Viewer** (proyecto datalake-gasco)
- **BigQuery User** (proyecto agent-intelligence-gasco)
- **Storage Object Viewer** (bucket miguel-test)
- **Storage Object Admin** (bucket agent-intelligence-zips)
- **Service Account Token Creator** (para signed URLs)

### ğŸš€ URLs Firmadas (Signed URLs)

El sistema implementa URLs firmadas para descargas seguras de archivos ZIP:

- Las URLs tienen formato: `https://storage.googleapis.com/bucket/file?X-Goog-Algorithm=...`
- VÃ¡lidas por 24 horas con expiraciÃ³n automÃ¡tica
- AutenticaciÃ³n usando credenciales impersonadas
- Sistema robusto con retry y compensaciÃ³n de clock skew

## ğŸ†• Sistema de Token Tracking

**Nuevo en octubre 2025**: El sistema ahora captura y persiste mÃ©tricas completas de tokens consumidos por Gemini API.

### CaracterÃ­sticas

- ğŸ“Š **Tokens de Gemini API**: Input, output, total, thinking, cached
- ğŸ“ **MÃ©tricas de Texto**: Caracteres y palabras de preguntas/respuestas
- ğŸ’° **Monitoreo de Costos**: EstimaciÃ³n automÃ¡tica de costos por conversaciÃ³n
- ğŸ“ˆ **AnÃ¡lisis de Performance**: CorrelaciÃ³n tokens vs tiempo de respuesta
- ğŸ’¾ **Cache Detection**: IdentificaciÃ³n de tokens reutilizados (optimizaciÃ³n)

### Campos Capturados

| Campo | DescripciÃ³n |
|-------|-------------|
| `prompt_token_count` | Tokens de entrada (prompt) |
| `candidates_token_count` | Tokens de salida (respuesta) |
| `total_token_count` | Total consumido |
| `thoughts_token_count` | Tokens de razonamiento interno |
| `cached_content_token_count` | Tokens cacheados (reutilizados) |
| `user_question_length` | Caracteres de la pregunta |
| `user_question_word_count` | Palabras de la pregunta |
| `agent_response_length` | Caracteres de la respuesta |
| `agent_response_word_count` | Palabras de la respuesta |

### ValidaciÃ³n de Tokens

```bash
# Ejecutar script de validaciÃ³n rÃ¡pida
python scripts/validation/quick_validate_tokens.py

# Ejecutar queries de anÃ¡lisis completo en BigQuery
# (usar archivo: sql_validation/validate_token_usage_tracking.sql)
```

ğŸ“š **DocumentaciÃ³n completa**: Ver `docs/TOKEN_USAGE_TRACKING.md`

## ğŸ§ª Pruebas

### Health Check

```bash
# Listar aplicaciones disponibles (equivalente a health check)
curl https://invoice-backend-yuhrx5x2ra-uc.a.run.app/list-apps
```

### Prueba Completa del Chatbot

```bash
curl -X POST https://invoice-backend-yuhrx5x2ra-uc.a.run.app/run \
  -H 'Content-Type: application/json' \
  -d '{
    "appName": "gcp-invoice-agent-app",
    "userId": "test-user",
    "sessionId": "test-session-123",
    "newMessage": {
      "parts": [{"text": "MuÃ©strame las facturas del mes pasado"}],
      "role": "user"
    }
  }'
```

### Tests Automatizados

```powershell
# Windows: Ejecutar suite completa de tests
.\tests\curl-tests\run-all-curl-tests.ps1

# Test individual
.\tests\scripts\test_facturas_diciembre_2019.ps1
```

Para pruebas mÃ¡s completas, consulta los archivos en la carpeta `tests/`.

## ğŸ“Š Monitoreo

El backend estÃ¡ configurado para enviar logs a Google Cloud Logging. Puedes monitorear la actividad y los errores del sistema desde:

- [Google Cloud Console > Logging](https://console.cloud.google.com/logs?project=agent-intelligence-gasco)
- [Google Cloud Console > Cloud Run > invoice-backend > Logs](https://console.cloud.google.com/run?project=agent-intelligence-gasco)

### MÃ©tricas de Tokens en BigQuery

```sql
-- Ver Ãºltimas conversaciones con tokens
SELECT
  conversation_id,
  timestamp,
  prompt_token_count as tokens_input,
  candidates_token_count as tokens_output,
  total_token_count as tokens_total,
  cached_content_token_count as tokens_cached,
  ROUND(response_time_ms / 1000.0, 1) as tiempo_seg
FROM `agent-intelligence-gasco.chat_analytics.conversation_logs`
WHERE prompt_token_count IS NOT NULL
ORDER BY timestamp DESC
LIMIT 10;
```

## ğŸ”— IntegraciÃ³n con Frontend

El backend expone endpoints RESTful basados en ADK para la comunicaciÃ³n con el frontend:

| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/run` | POST | Endpoint principal para ejecutar conversaciones |
| `/run_sse` | GET | Streaming server-sent events del chatbot |
| `/list-apps` | GET | Lista las aplicaciones ADK disponibles |
| `/apps/{app_name}/users/{user_id}/sessions/{session_id}` | GET/POST | GestiÃ³n de sesiones |
| `/apps/{app_name}/users/{user_id}/sessions` | GET/POST | Crear y listar sesiones |
| `/gcs?url=` | GET | Proxy para descargas con signed URLs (PDF/ZIP) |

**Nota**: El sistema ADK no incluye endpoint `/health`. Para verificar estado usar `/list-apps`.

**URL ProducciÃ³n**: `https://invoice-backend-yuhrx5x2ra-uc.a.run.app`

Consulta la documentaciÃ³n completa de la API ADK en `docs/adk_api_documentation.json`.

## ğŸ› ï¸ SoluciÃ³n de Problemas Comunes

### 1. Error 'Module not found'
**SoluciÃ³n**: AsegÃºrate de que todas las dependencias estÃ¡n instaladas.
```bash
pip install -r requirements.txt
```

### 2. Error de conexiÃ³n a BigQuery
**SoluciÃ³n**: Verifica que las credenciales de servicio estÃ¡n configuradas correctamente.
```bash
gcloud auth application-default login
```

### 3. Herramientas MCP no encontradas
**SoluciÃ³n**: AsegÃºrate de haber descargado los binarios segÃºn las instrucciones en `mcp-toolbox/README.md`.

### 4. Error en el procesamiento de PDF
**SoluciÃ³n**: Verifica que el servidor PDF estÃ¡ en ejecuciÃ³n y accesible en el puerto configurado.

### 5. Error "Forbidden" en descargas
**SoluciÃ³n**: Verifica que las signed URLs estÃ¡n implementadas correctamente y que la service account tiene permisos de Storage Object Admin.

### 6. Tokens no se capturan en BigQuery
**SoluciÃ³n**:
```bash
# 1. Verificar que el schema estÃ¡ actualizado
python scripts/bigquery/apply_token_schema_update.py

# 2. Verificar logs del agente
grep "Usage metadata capturado" logs/logs-adk.txt

# 3. Reiniciar el servidor ADK
```

## ğŸ“š DocumentaciÃ³n Adicional

- [CLAUDE.md](./docs/ai-assistants/CLAUDE.md) - Instrucciones para Claude Code
- [DEBUGGING_CONTEXT.md](./docs/debugging/DEBUGGING_CONTEXT.md) - Contexto de debugging y issues resueltos
- [TOKEN_USAGE_TRACKING.md](./docs/TOKEN_USAGE_TRACKING.md) - DocumentaciÃ³n completa del sistema de tokens
- [SETUP_INFRAESTRUCTURA.md](./infrastructure/SETUP_INFRAESTRUCTURA.md) - Setup de infraestructura GCP
- [DEPLOYMENT_ARCHITECTURE.md](./docs/DEPLOYMENT_ARCHITECTURE.md) - Arquitectura de deployment
- [REPOSITORY_ANALYSIS.md](./docs/REPOSITORY_ANALYSIS.md) - AnÃ¡lisis de estructura del repositorio

## ğŸ“œ Licencia

Este proyecto es propiedad de **Gasco** y **Option**. Todos los derechos reservados.

## ğŸ‘¥ Contacto y Soporte

Para soporte tÃ©cnico o consultas, contacta al equipo de desarrollo en [soporte-tech@option.cl](mailto:soporte-tech@option.cl).

---

**Ãšltima revisiÃ³n**: 2 de octubre de 2025
**VersiÃ³n Backend**: v20251002-120414
**Estado**: âœ… Production Ready
